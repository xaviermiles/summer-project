{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DigWaU54EV9Q"
   },
   "source": [
    "# Satellite imagery building segmentation MaskRCNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "joxeeOotBvnC",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "d4d3e274-3268-4f6a-efe7-288e07ff924e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/Colab Notebooks\n",
      "Collecting mrcnn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/3d/56e05c297a1f464a042b2c47bcd9e5f2d452ce0e5eca3894f7cbdcaee758/mrcnn-0.2.tar.gz (51kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 3.3MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: mrcnn\n",
      "  Building wheel for mrcnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for mrcnn: filename=mrcnn-0.2-cp36-none-any.whl size=54932 sha256=bd55bac75fb4b64e6b2c9601bb149d45cacbfe713ea1b92cd1e016c7c42bc7db\n",
      "  Stored in directory: /root/.cache/pip/wheels/11/ed/28/e550ddc897c04c336b923eae4eb35c9aae993d20ce39d9cc40\n",
      "Successfully built mrcnn\n",
      "Installing collected packages: mrcnn\n",
      "Successfully installed mrcnn-0.2\n",
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/My\\ Drive/Colab\\ Notebooks\n",
    "!pip install mrcnn\n",
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-f9gRKYvEV9Y"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XClMTItR7uTe"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oF4xVzjbEV9a",
    "outputId": "75465c57-48de-4216-ff20-e9c8844e24f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucsail/anaconda3/envs/SAIL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ucsail/anaconda3/envs/SAIL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ucsail/anaconda3/envs/SAIL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ucsail/anaconda3/envs/SAIL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ucsail/anaconda3/envs/SAIL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ucsail/anaconda3/envs/SAIL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 1.12.0\n",
      "Root directory: /home/ucsail/rural_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import skimage.draw\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "# local python file:\n",
    "import semantic_utils\n",
    "\n",
    "\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.getcwd())\n",
    "print(f\"Root directory: {ROOT_DIR}\")\n",
    "LOGS_DIR = os.path.join(ROOT_DIR, \"MASK_RCNN\", \"logs_MW\")\n",
    "\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"MASK_RCNN\", \"mask_rcnn_coco.h5\")\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "v6cc2VrcEV9d"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "#  Configurations\n",
    "############################################################\n",
    "\n",
    "\n",
    "class LandCoverConfig(Config):\n",
    "    \"\"\"\n",
    "    Includes 2 labelled classes (water and vegetation) and the background\n",
    "    \"\"\"\n",
    "    NAME = \"LandCover\"\n",
    "\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    NUM_CLASSES = 1 + 7  # background + 7 land cover types\n",
    "\n",
    "    STEPS_PER_EPOCH = 1000\n",
    "\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "    \n",
    "    LEARNING_RATE = 0.001\n",
    "    \n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "\n",
    "config = LandCoverConfig()\n",
    "# config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dX9s4Wf5EV9g"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "#  Dataset\n",
    "############################################################\n",
    "\n",
    "class LandCoverDataset(utils.Dataset):\n",
    "    \n",
    "    def __init__(self, class_map=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.MW_class_to_colours = {\n",
    "            'Artificial Surfaces': 1,\n",
    "            'Bare or Lightly-vegetated Surfaces': 2,\n",
    "            'Water Bodies': 3,\n",
    "            'Cropland': 4,\n",
    "            'Grassland, Sedgeland and Marshland': 5,\n",
    "            'Scrub and Shrubland': 6,\n",
    "            'Forest': 7\n",
    "        }\n",
    "\n",
    "    def load_LandCover(self, dataset_dir, subset):\n",
    "        \"\"\"Load a subset of the LandCover dataset.  \n",
    "        dataset_dir: Root directory of the dataset.\n",
    "        subset: Subset to load: train or val\n",
    "        \"\"\"\n",
    "        for class_name, class_num in self.MW_class_to_colours.items():\n",
    "            self.add_class(\"LandCover\", class_num, class_name)\n",
    "        \n",
    "        assert subset in [\"train\", \"train_aug\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "        annotations_dir = os.path.join(dataset_dir, f\"MW_{subset}.json\")\n",
    "\n",
    "        annotations = json.load(open(annotations_dir))\n",
    "        annotations = list(annotations.values())  # don't need the dict keys\n",
    "        annotations = [a for a in annotations if a['regions']]  # only images with regions\n",
    "\n",
    "        for a in annotations:\n",
    "            image_path = os.path.join(dataset_dir, a['filename'])\n",
    "            \n",
    "            if os.path.exists(image_path):\n",
    "                polygons = [r['shape_attributes'] for r in a['regions']]\n",
    "                \n",
    "                for r in a['regions']:\n",
    "                    if 'label' not in r['region_attributes'].keys():\n",
    "                        print(f\"FILE CONTAINS REGION THAT DOES NOT HAVE CLASS LABEL:\", a['filename'])\n",
    "\n",
    "                class_names = [r['region_attributes']['label'] for r in a['regions']]\n",
    "                class_ids = [self.MW_class_to_colours[a] for a in class_names]\n",
    "                \n",
    "                image = skimage.io.imread(image_path)\n",
    "                height, width = image.shape[:2]\n",
    "\n",
    "                self.add_image(\n",
    "                    \"LandCover\",\n",
    "                    image_id=a['filename'], \n",
    "                    path=image_path,\n",
    "                    class_id=class_ids,\n",
    "                    width=width, height=height,\n",
    "                    polygons=polygons)\n",
    "            else:\n",
    "                print(f\"File does not exist: {image_path}\")\n",
    "                \n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_id: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"LandCover\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'][::2], p['all_points_x'][::2])\n",
    "            mask[rr, cc, i] = 1\n",
    "        \n",
    "        classes = np.asarray(image_info[\"class_id\"])\n",
    "        return mask, classes\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        #print(image_id)\n",
    "        if info[\"source\"] == \"LandCover\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RAwu1V3-EV9j",
    "outputId": "7cf35b57-bf26-4e0c-9fdb-b90817427749"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: /home/ucsail/rural_images/data V2.0\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = os.path.join(ROOT_DIR, \"data V2.0\")\n",
    "print(f\"Dataset path: {dataset_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BaSM5BUiEV9l",
    "outputId": "d5a4dacc-624f-439a-bdfc-666c68f356be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 1212\n"
     ]
    }
   ],
   "source": [
    "dataset_train = LandCoverDataset()\n",
    "dataset_train.load_LandCover(dataset_dir, \"train\")\n",
    "dataset_train.prepare()\n",
    "\n",
    "print(f\"Number of training images: {len(dataset_train.image_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZjGzDRVEV9m",
    "outputId": "e4632bc3-15bc-44c8-cebf-6e2edc3098d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation images: 304\n"
     ]
    }
   ],
   "source": [
    "dataset_val = LandCoverDataset()\n",
    "dataset_val.load_LandCover(dataset_dir, \"val\")\n",
    "dataset_val.prepare()\n",
    "\n",
    "print(f\"Number of validation images: {len(dataset_val.image_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear previously-run models from memory\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9xsE0eWYEV9n"
   },
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=LOGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "O4Tl-p-IEV9o"
   },
   "outputs": [],
   "source": [
    "init_with = \"coco\"\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    model.load_weights(model.find_last()[1], by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEXNFiw8EV9t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/ucsail/rural_images/MASK_RCNN/logs_MW/landcover20210209T1634/mask_rcnn_landcover_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucsail/anaconda3/envs/SAIL/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/ucsail/anaconda3/envs/SAIL/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1000/1000 [==============================] - 989s 989ms/step - loss: 4.5811 - rpn_class_loss: 0.4586 - rpn_bbox_loss: 2.7276 - mrcnn_class_loss: 0.3459 - mrcnn_bbox_loss: 0.5038 - mrcnn_mask_loss: 0.5452 - val_loss: 4.8607 - val_rpn_class_loss: 0.5394 - val_rpn_bbox_loss: 2.8466 - val_mrcnn_class_loss: 0.3072 - val_mrcnn_bbox_loss: 0.6363 - val_mrcnn_mask_loss: 0.5313\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 1189s 1s/step - loss: 4.4441 - rpn_class_loss: 0.3950 - rpn_bbox_loss: 2.7345 - mrcnn_class_loss: 0.3246 - mrcnn_bbox_loss: 0.4590 - mrcnn_mask_loss: 0.5309 - val_loss: 5.0123 - val_rpn_class_loss: 0.4160 - val_rpn_bbox_loss: 2.9891 - val_mrcnn_class_loss: 0.3405 - val_mrcnn_bbox_loss: 0.7085 - val_mrcnn_mask_loss: 0.5581\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 1038s 1s/step - loss: 4.3997 - rpn_class_loss: 0.3751 - rpn_bbox_loss: 2.7151 - mrcnn_class_loss: 0.3359 - mrcnn_bbox_loss: 0.4647 - mrcnn_mask_loss: 0.5089 - val_loss: 4.9667 - val_rpn_class_loss: 0.4030 - val_rpn_bbox_loss: 2.9213 - val_mrcnn_class_loss: 0.2938 - val_mrcnn_bbox_loss: 0.7398 - val_mrcnn_mask_loss: 0.6089\n",
      "Epoch 4/30\n",
      " 999/1000 [============================>.] - ETA: 1s - loss: 4.2590 - rpn_class_loss: 0.3450 - rpn_bbox_loss: 2.7009 - mrcnn_class_loss: 0.2843 - mrcnn_bbox_loss: 0.4301 - mrcnn_mask_loss: 0.4987"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "########    Training     ##########\n",
    "###################################\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=30, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKjO5SWkEV9u"
   },
   "source": [
    "# Load previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_-Ob-byEV9v"
   },
   "outputs": [],
   "source": [
    "############################################\n",
    "###########    Configurations    ###########\n",
    "############################################\n",
    "class InferenceConfig(LandCoverConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "# inference_config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAwoNs8kEV9v",
    "outputId": "586086a3-803d-4c8c-c60e-ac20405d1c7e"
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "####     Create Model and Load Trained Weights      ####\n",
    "########################################################\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=LOGS_DIR, config=inference_config)\n",
    "\n",
    "model_path = model.find_last()\n",
    "# model_path = os.path.join(LOGS_DIR, \"landcover20210119T1944\", \"mask_rcnn_landcover_0070.h5\")\n",
    "\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QA2QHA7aNIH0"
   },
   "source": [
    "# Display prediction for example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "dpy93IyNEV9w",
    "outputId": "57f4da7b-044f-4bf1-a9e8-bf5021e78cb3"
   },
   "outputs": [],
   "source": [
    "# test_num = random.choice(range(len(dataset_val.image_ids)))\n",
    "test_num = 147\n",
    "print(\"NUMBER: \", test_num)\n",
    "image_id = dataset_val.image_ids[test_num]\n",
    "test_img, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", test_img)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(test_img, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_val.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 993
    },
    "id": "SBW3ppxiEV9w",
    "outputId": "b663818a-c3dc-41ee-e741-7b1a89398cfe"
   },
   "outputs": [],
   "source": [
    "results = model.detect([test_img], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(test_img, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "lEKkL_6-7uT5",
    "outputId": "5982041c-4895-4d30-aa7d-6275c6bc480c"
   },
   "outputs": [],
   "source": [
    "water_vege_converter = {\n",
    "    1: (0, 0, 255),  # water\n",
    "    2: (0, 255, 0)  # vegetation\n",
    "}\n",
    "test_target_fname = os.path.basename(os.path.normpath(dataset_val.image_reference(test_num))\n",
    "test_target_fpath = os.path.join(dataset_dir, \"val_class_images_manual\", test_target_fname)\n",
    "test_rgb_target_img = semantic_utils.convert_to_rgb(np.array(load_img(test_target_fpath))[:, :, 0], water_vege_converter)\n",
    "test_rgb_target_img_square = semantic_utils.resize(test_rgb_target_img, max_dim=1024)\n",
    "\n",
    "test_pred_img = semantic_utils.convert_mrcnn_instances_to_semantic(r, config)\n",
    "test_rgb_pred_img = semantic_utils.convert_to_rgb(test_pred_img, water_vege_converter)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 40))\n",
    "ax[0].imshow(test_rgv_target_img_square)\n",
    "ax[0].set(title=\"Actual\")\n",
    "ax[1].imshow(test_rgb_pred_img)\n",
    "ax[1].set(title=\"Predicted\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"THESE ARE METRICS FOR A SINGLE IMAGE!!!\")\n",
    "test_paths = [test_target_fpath]\n",
    "test_pred_imgs = np.expand_dims(test_pred_img, axis=0)\n",
    "test_result = semantic_utils.compute_metrics(test_paths, test_pred_imgs, config.NUM_CLASSES, config.IMAGE_MAX_DIM, display=True)\n",
    "print(\"THESE ARE METRICS FOR A SINGLE IMAGE!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrW-dCZ8EV9y"
   },
   "source": [
    "# Evaluation of pixel-wise classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r_uoRvQW7uT6",
    "outputId": "20e0a2df-cf67-4c27-a410-0552aa25974e"
   },
   "outputs": [],
   "source": [
    "target_image_paths = []\n",
    "pred_images = np.zeros(shape=(len(dataset_val.image_ids), config.IMAGE_MAX_DIM, config.IMAGE_MAX_DIM), dtype=np.uint8)\n",
    "\n",
    "print(f\"Number of images processed:\", end=\"\", flush=True)\n",
    "\n",
    "for image_id in dataset_val.image_ids:\n",
    "    # print progress\n",
    "    if (image_id + 1) % 10 == 0 or (image_id + 1) == len(dataset_val.image_ids):\n",
    "        print(f\"  {image_id + 1}\", end=\"\", flush=True)\n",
    "    \n",
    "    # get target (mask) image filepath and append to list\n",
    "    original_image_path = dataset_val.image_reference(image_id)\n",
    "    original_image = np.array(load_img(original_image_path))\n",
    "    original_image_square = utils.resize_image(original_image, max_dim=config.IMAGE_MAX_DIM)[0]\n",
    "    image_filename = os.path.basename(os.path.normpath(original_image_path))\n",
    "    \n",
    "    target_image_path = os.path.join(dataset_dir, \"val_class_images_manual\", image_filename)\n",
    "    target_image_paths.append(target_image_path)\n",
    "    \n",
    "    # Predict instances using Mask R-CNN and convert to 2D class map\n",
    "    result = model.detect([original_image_square], verbose=False)[0]\n",
    "    pred_image = semantic_utils.convert_mrcnn_instances_to_semantic(result, config)\n",
    "    \n",
    "    # Write predicted 2D class map to 3D array\n",
    "    pred_images[image_id, :, :] = pred_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VA0bj8Aq7uUD",
    "outputId": "e95ecc0e-55d4-42b5-9f8a-6fa70ef2007e"
   },
   "outputs": [],
   "source": [
    "results = semantic_utils.compute_metrics(target_image_paths, pred_images, config.NUM_CLASSES, config.IMAGE_MAX_DIM, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z52yhQuaN-Q5",
    "outputId": "bafd135f-3b2e-4b3a-feab-d76595bed597"
   },
   "outputs": [],
   "source": [
    "semantic_utils.print_metric_results(results, config.NUM_CLASSES)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "running_Mask_RCNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
